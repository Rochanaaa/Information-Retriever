{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import emoji\n",
    "import time\n",
    "import string\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "import nltk\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset for subjective data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>comment</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NC and NH.</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>You do know west teams play against west teams...</td>\n",
       "      <td>nba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>They were underdogs earlier today, but since G...</td>\n",
       "      <td>nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>This meme isn't funny none of the \"new york ni...</td>\n",
       "      <td>BlackPeopleTwitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>I could use one of those tools.</td>\n",
       "      <td>MaddenUltimateTeam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            comment  \\\n",
       "0      0                                         NC and NH.   \n",
       "1      0  You do know west teams play against west teams...   \n",
       "2      0  They were underdogs earlier today, but since G...   \n",
       "3      0  This meme isn't funny none of the \"new york ni...   \n",
       "4      0                    I could use one of those tools.   \n",
       "\n",
       "            subreddit  \n",
       "0            politics  \n",
       "1                 nba  \n",
       "2                 nfl  \n",
       "3  BlackPeopleTwitter  \n",
       "4  MaddenUltimateTeam  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load reddit dataset\n",
    "sarcasm_df = pd.read_csv('sarcasm.csv', usecols=['comment', 'label', 'subreddit'])\n",
    "\n",
    "sarcasm_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label         0\n",
       "comment      55\n",
       "subreddit     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sarcasm_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label        0\n",
       "comment      0\n",
       "subreddit    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop null\n",
    "sarcasm_df = sarcasm_df.dropna()\n",
    "sarcasm_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>comment</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>49060</td>\n",
       "      <td>4123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>You forgot the</td>\n",
       "      <td>AskReddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>70</td>\n",
       "      <td>3279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.498420</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.500003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               label         comment  subreddit\n",
       "count   50000.000000           50000      50000\n",
       "unique           NaN           49060       4123\n",
       "top              NaN  You forgot the  AskReddit\n",
       "freq             NaN              70       3279\n",
       "mean        0.498420             NaN        NaN\n",
       "std         0.500003             NaN        NaN\n",
       "min         0.000000             NaN        NaN\n",
       "25%         0.000000             NaN        NaN\n",
       "50%         0.000000             NaN        NaN\n",
       "75%         1.000000             NaN        NaN\n",
       "max         1.000000             NaN        NaN"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select relevant subreddits to use\n",
    "# subreddits = ['technology', 'MachineLearning']\n",
    "# df = sarcasm_df[sarcasm_df.subreddit.isin(subreddits)].reset_index(drop=True)\n",
    "# df = sarcasm_df.sample(50000, random_state=11)\n",
    "# df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5720, 3)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mix subreddits with those that we want\n",
    "# Note that this dataset is generated in 2017, so most of the gen AI subreddits have not existed\n",
    "subreddits = ['technology', 'MachineLearning']\n",
    "\n",
    "mask = sarcasm_df.subreddit.isin(subreddits)\n",
    "tech_df = sarcasm_df[mask].reset_index(drop=True)\n",
    "other_df = sarcasm_df[~mask].reset_index(drop=True)\n",
    "tech_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>comment</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>48842</td>\n",
       "      <td>3887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>You forgot the</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>78</td>\n",
       "      <td>5928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.511260</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.499878</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               label         comment   subreddit\n",
       "count   50000.000000           50000       50000\n",
       "unique           NaN           48842        3887\n",
       "top              NaN  You forgot the  technology\n",
       "freq             NaN              78        5928\n",
       "mean        0.511260             NaN         NaN\n",
       "std         0.499878             NaN         NaN\n",
       "min         0.000000             NaN         NaN\n",
       "25%         0.000000             NaN         NaN\n",
       "50%         1.000000             NaN         NaN\n",
       "75%         1.000000             NaN         NaN\n",
       "max         1.000000             NaN         NaN"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 50000 - len(tech_df)\n",
    "df = sarcasm_df.sample(N, random_state=11)\n",
    "df = pd.concat([df, tech_df])\n",
    "df = df.sample(frac=1).reset_index(drop=True)      # Shuffle rows\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>My friends in San Marco said they have no floo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>My guess is on the parade reaching Waveland...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Huk's Mothership rush back in the day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>\"You can't mirror mirrored items and all uniqu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Take a look at Edward Snowden's case, and you ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                           sentence\n",
       "0      0  My friends in San Marco said they have no floo...\n",
       "1      1     My guess is on the parade reaching Waveland...\n",
       "2      0              Huk's Mothership rush back in the day\n",
       "3      0  \"You can't mirror mirrored items and all uniqu...\n",
       "4      0  Take a look at Edward Snowden's case, and you ..."
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename comment column\n",
    "df = df.rename(columns={\"comment\": \"sentence\"})\n",
    "df.drop(columns=['subreddit'], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_not_ASCII(text):\n",
    "    text = str(text)\n",
    "    text = ''.join([word for word in text if word in string.printable])\n",
    "#     print(text)\n",
    "    return text\n",
    "\n",
    "def replace_emoticons(text):\n",
    "    text = text.replace(\"<3\", \"heart \")\n",
    "    text = re.sub('>:-?\\'?\"?\\(+', 'angry ', text)\n",
    "    text = re.sub('\\)+:-?\\'?\"?:<', 'angry ', text)\n",
    "    text = re.sub(':-?\\'?\"?(o+|O+|0+)', 'surprised ', text)\n",
    "    text = re.sub(':-?\\'?\"?(\\)+|>+|D+)', 'smile ', text)\n",
    "    text = re.sub('(\\(+|<+)-?\\'?\"?:', 'smile ', text)\n",
    "    text = re.sub(':-?\\'?\"?\\(+', 'sad ', text)\n",
    "    text = re.sub('(\\)+|>+|D+)-?\\'?\"?:', 'sad ', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "def text_preprocessing(text):\n",
    "    # Clean dataset\n",
    "    text = replace_emoticons(text)                           # convert emoticon to text\n",
    "    text = emoji.demojize(text, delimiters=(\"\", \" \"))        # convert emoji to text\n",
    "    text = remove_not_ASCII(text)                            # remove non-ASCII characters\n",
    "\n",
    "    text = re.sub('<br />', '', text)                        # remove <br />\n",
    "    text = re.sub('^https?:\\/\\/S+', '', text)                # remove URLs\n",
    "    \n",
    "    text = re.sub('u/\\S+', 'user', text)                     # replace user mentions\n",
    "    text = re.sub('@\\S+', 'user', text)\n",
    "    text = re.sub('r/\\S+', 'subreddit', text)                # replace subreddit mentions\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>My friends in San Marco said they have no floo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>My guess is on the parade reaching Waveland...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Huk's Mothership rush back in the day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>\"You can't mirror mirrored items and all uniqu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Take a look at Edward Snowden's case, and you ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                           sentence\n",
       "0      0  My friends in San Marco said they have no floo...\n",
       "1      1     My guess is on the parade reaching Waveland...\n",
       "2      0              Huk's Mothership rush back in the day\n",
       "3      0  \"You can't mirror mirrored items and all uniqu...\n",
       "4      0  Take a look at Edward Snowden's case, and you ..."
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentence'] = df['sentence'].apply(text_preprocessing)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    25563\n",
       "0    24437\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0, 1: 1}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possible_labels = df.label.unique()\n",
    "\n",
    "label_dict = {}\n",
    "for index, possible_label in enumerate(possible_labels):\n",
    "    label_dict[possible_label] = index\n",
    "label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(df.index.values, \n",
    "                                                  df.label.values, \n",
    "                                                  test_size=0.2, \n",
    "                                                  random_state=11, \n",
    "                                                  stratify=df.label.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['data_type'] = ['not_set']*df.shape[0]\n",
    "\n",
    "df.loc[X_train, 'data_type'] = 'train'\n",
    "df.loc[X_val, 'data_type'] = 'val'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th>data_type</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>train</th>\n",
       "      <td>19550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>4887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>train</th>\n",
       "      <td>20450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>5113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 sentence\n",
       "label data_type          \n",
       "0     train         19550\n",
       "      val            4887\n",
       "1     train         20450\n",
       "      val            5113"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['label', 'data_type']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>57.962420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>75.391402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>47.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>76.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           sentence\n",
       "count  50000.000000\n",
       "mean      57.962420\n",
       "std       75.391402\n",
       "min        1.000000\n",
       "25%       27.000000\n",
       "50%       47.000000\n",
       "75%       76.000000\n",
       "max    10000.000000"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine value of max_seq_len\n",
    "review_len = pd.DataFrame(df['sentence'].apply(len))\n",
    "review_len.hist()\n",
    "plt.show()\n",
    "review_len.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', \n",
    "                                          do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/FYP/c200129/.conda/envs/test/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2645: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "encoded_data_train = tokenizer.batch_encode_plus(\n",
    "    df[df.data_type=='train'].sentence.values, \n",
    "    add_special_tokens=True, \n",
    "    return_attention_mask=True, \n",
    "    pad_to_max_length=True, \n",
    "    max_length=256, \n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "encoded_data_val = tokenizer.batch_encode_plus(\n",
    "    df[df.data_type=='val'].sentence.values, \n",
    "    add_special_tokens=True, \n",
    "    return_attention_mask=True, \n",
    "    pad_to_max_length=True, \n",
    "    max_length=256, \n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "input_ids_train = encoded_data_train['input_ids']\n",
    "attention_masks_train = encoded_data_train['attention_mask']\n",
    "labels_train = torch.tensor(df[df.data_type=='train'].label.values)\n",
    "\n",
    "input_ids_val = encoded_data_val['input_ids']\n",
    "attention_masks_val = encoded_data_val['attention_mask']\n",
    "labels_val = torch.tensor(df[df.data_type=='val'].label.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 10000)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_train), len(dataset_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
    "                                                      num_labels=len(label_dict),\n",
    "                                                      output_attentions=False,\n",
    "                                                      output_hidden_states=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "dataloader_train = DataLoader(dataset_train, \n",
    "                              sampler=RandomSampler(dataset_train), \n",
    "                              batch_size=batch_size)\n",
    "\n",
    "dataloader_validation = DataLoader(dataset_val, \n",
    "                                   sampler=SequentialSampler(dataset_val), \n",
    "                                   batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/FYP/c200129/.conda/envs/test/lib/python3.10/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr=1e-5, \n",
    "                  eps=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Early stopper to stop when the F1 Score prediction drops \n",
    "class EarlyStopper:\n",
    "    def __init__(self, patience=3, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.min_f1_score = 0\n",
    "        self.min_accuracy = 0\n",
    "\n",
    "    def early_stop_f1(self, f1_score):\n",
    "        if f1_score > self.min_f1_score:\n",
    "            self.min_f1_score = f1_score\n",
    "            self.counter = 0\n",
    "        elif f1_score <= (self.min_f1_score + self.min_delta):\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.counter = 0\n",
    "                self.f1_score = 0\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def early_stop_accuracy(self, accuracy):\n",
    "        if accuracy > self.min_accuracy:\n",
    "            self.min_accuracy = accuracy\n",
    "            self.counter = 0\n",
    "        elif accuracy < (self.min_accuracy + self.min_delta):\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.counter = 0\n",
    "                self.min_accuracy = 0\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 25\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps=0,\n",
    "                                            num_training_steps=len(dataloader_train)*epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def f1_score_func(preds, labels):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return f1_score(labels_flat, preds_flat, average='weighted')\n",
    "\n",
    "def accuracy_per_class(preds, labels):\n",
    "    label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
    "    \n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    \n",
    "    total_preds = 0\n",
    "    total_correct = 0\n",
    "\n",
    "    for label in np.unique(labels_flat):\n",
    "        y_preds = preds_flat[labels_flat==label]\n",
    "        y_true = labels_flat[labels_flat==label]\n",
    "        \n",
    "        total_preds += len(y_preds)\n",
    "        num_correct = len(y_preds[y_preds==label])\n",
    "        total_correct += num_correct\n",
    "        acc = num_correct/len(y_true)\n",
    "        \n",
    "        print(f'Class: {label_dict_inverse[label]}')\n",
    "        print(f'Accuracy: {acc}')\n",
    "        print(f'Accuracy (in percentage): {acc*100:.3f}\\n')\n",
    "    \n",
    "    print(f'Total accuracy: {(total_correct/total_preds)*100:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "seed_val = 11\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader_val):\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals = [], []\n",
    "    \n",
    "    for batch in dataloader_val:\n",
    "        \n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }\n",
    "\n",
    "        with torch.no_grad():        \n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_val_total += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids)\n",
    "    \n",
    "    loss_val_avg = loss_val_total/len(dataloader_val) \n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "            \n",
    "    return loss_val_avg, predictions, true_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ed068dc869945e7ae4a2bdb535607d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/1250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "Training loss: 0.5806402681350707\n",
      "Validation loss: 0.5349455054004353\n",
      "F1 Score (Weighted): 0.7315498762634955\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68276c0a45ba48cb829a09ae362d4d8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/1250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "early_stopper = EarlyStopper(patience=3, min_delta=0)\n",
    "\n",
    "e = 0\n",
    "\n",
    "for epoch in tqdm(range(1, epochs+1)):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    loss_train_total = 0\n",
    "\n",
    "    progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n",
    "    \n",
    "    for batch in progress_bar:\n",
    "        model.zero_grad()\n",
    "\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }       \n",
    "\n",
    "        outputs = model(**inputs)\n",
    "        \n",
    "        loss = outputs[0]\n",
    "        loss_train_total += loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n",
    "              \n",
    "    tqdm.write(f'\\nEpoch {epoch}')\n",
    "    \n",
    "    loss_train_avg = loss_train_total/len(dataloader_train)            \n",
    "    tqdm.write(f'Training loss: {loss_train_avg}')\n",
    "    \n",
    "    val_loss, predictions, true_vals = evaluate(dataloader_validation)\n",
    "    val_f1 = f1_score_func(predictions, true_vals)\n",
    "    tqdm.write(f'Validation loss: {val_loss}')\n",
    "    tqdm.write(f'F1 Score (Weighted): {val_f1}')\n",
    "    \n",
    "    # Check for early stop\n",
    "    if early_stopper and early_stopper.early_stop_f1(val_f1):\n",
    "        e = epoch\n",
    "        print(f\"Early stopping at epoch {epoch} due to no improvement in f1 score.\")\n",
    "        torch.save(model.state_dict(), f'finetuned_BERT_sarcasm_mixed_epoch_{e}.model')\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model and get accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
    "                                                      num_labels=len(label_dict),\n",
    "                                                      output_attentions=False,\n",
    "                                                      output_hidden_states=False)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded, getting predictions...\n",
      "Class: 0\n",
      "Accuracy: 0.6674641148325359\n",
      "Accuracy (in percentage): 66.746\n",
      "\n",
      "Class: 1\n",
      "Accuracy: 0.7656500802568218\n",
      "Accuracy (in percentage): 76.565\n",
      "\n",
      "Total accuracy: 71.640\n",
      "F1 score: 0.7157349193136776\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(f'finetuned_BERT_sarcasm_mixed_epoch_{e}.model', map_location=torch.device('cuda')))\n",
    "print('Model loaded, getting predictions...')\n",
    "_, predictions, true_vals = evaluate(dataloader_validation)\n",
    "accuracy_per_class(predictions, true_vals)\n",
    "f1_score = f1_score_func(predictions, true_vals)\n",
    "print(f'F1 score: {f1_score:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test with custom data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter some text: wow\n",
      "Prediction: 1\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(f'finetuned_BERT_sarcasm_epoch_{e}.model', map_location=torch.device('cuda')))\n",
    "\n",
    "text = input(\"Enter some text: \")\n",
    "text = text_preprocessing(text)\n",
    "\n",
    "encoded_text = tokenizer.encode_plus(\n",
    "    text, \n",
    "    add_special_tokens=True, \n",
    "    return_attention_mask=True, \n",
    "    pad_to_max_length=True, \n",
    "    max_length=256, \n",
    "    return_tensors='pt'\n",
    ")\n",
    "# print(encoded_text)\n",
    "\n",
    "input_ids_text = encoded_text['input_ids']\n",
    "attention_masks_text = encoded_text['attention_mask']\n",
    "\n",
    "dataset = TensorDataset(input_ids_text, attention_masks_text)\n",
    "dataloader = DataLoader(dataset, \n",
    "                        sampler=RandomSampler(dataset), \n",
    "                        batch_size=1)\n",
    "\n",
    "for batch in dataloader:\n",
    "    batch = tuple(b.to(device) for b in batch)\n",
    "    inputs = {'input_ids':      batch[0],\n",
    "              'attention_mask': batch[1]\n",
    "             }\n",
    "\n",
    "    with torch.no_grad():        \n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs[0]\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "\n",
    "#     print(logits)\n",
    "    pred = np.argmax(logits, axis=1).flatten()[0]\n",
    "    print(f'Prediction: {list(label_dict.keys())[pred]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
